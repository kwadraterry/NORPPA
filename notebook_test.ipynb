{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup autoreload, warnings and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, Markdown\n",
    "def print_heading(string):\n",
    "    display(Markdown(f\"# {string}\"))\n",
    "def print_subheading(string):\n",
    "    display(Markdown(f\"## {string}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the visibility of cuda devices (in case your system contains more than one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from config import config\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import wget\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from torchvision.datasets.utils import download_url\n",
    "from datasets import COCOImageDataset, DatasetSlice\n",
    "\n",
    "from tools import apply_pipeline, crop_step, curry, apply_pipeline_cocodataset, get_save_step\n",
    "from tonemapping.tonemapping import tonemap, tonemap_step\n",
    "from segmentation.segmentation import segment\n",
    "from pattern_extraction.extract_pattern import extract_pattern\n",
    "from reidentification.identify import encode_single, encode_pipeline, create_database, identify, identify_single\n",
    "from reidentification.visualisation import visualise_match\n",
    "from simple_database import SimpleDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a configuration file.\n",
    "You can change the default parameters in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(cfg[\"dataset_dir\"])\n",
    "\n",
    "if not dataset_dir.exists():\n",
    "    \n",
    "    print(\"Download and extract dataset\")\n",
    "    # Get a single use download link from https://etsin.fairdata.fi/dataset/22b5191e-f24b-4457-93d3-95797c900fc0/data\n",
    "    # You will only need \"full images.zip\" for the reidentification, generate a link to that.\n",
    "    dataset_url = \"\"\n",
    "    \n",
    "    print(f'Creating directory \"{dataset_dir}\"')\n",
    "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file = wget.download(dataset_url.replace(\" \", \"%20\"), out=str(dataset_dir))\n",
    "    print()\n",
    "    print(f'Extracting \"{file}\"')\n",
    "    zip_f = zipfile.ZipFile(file, 'r')\n",
    "    zip_f.extractall(dataset_dir)\n",
    "    zip_f.close()\n",
    "    Path(file).unlink()\n",
    "\n",
    "print(f'SealID dataset is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(cfg[\"dataset_dir\"])/\"full images\"\n",
    "\n",
    "database_dataset = COCOImageDataset(dataset_dir/\"source_database\", dataset_dir/\"annotation.csv\", \"database\")\n",
    "query_dataset = COCOImageDataset(dataset_dir/\"source_query\", dataset_dir/\"annotation.csv\", \"query\")\n",
    "\n",
    "\n",
    "segmented_database_dataset = COCOImageDataset(dataset_dir/\"segmented_database\", dataset_dir/\"annotation.csv\", \"database\")\n",
    "segmented_query_dataset = COCOImageDataset(dataset_dir/\"segmented_query\", dataset_dir/\"annotation.csv\", \"query\")\n",
    "\n",
    "img_data = query_dataset[3]\n",
    "print(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = img_data\n",
    "\n",
    "print_heading(\"Input image\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply tonemapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to install pfstmo package with\n",
    "# sudo apt-get install pfstmo\n",
    "\n",
    "tonemapped_img = tonemap(img)\n",
    "\n",
    "print_heading(\"Tonemapped image\")\n",
    "plt.imshow(tonemapped_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment and crop an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_step = curry(segment, cfg[\"detectron_predictor\"], instance_segmentation=False)\n",
    "\n",
    "segmented_img, label = apply_pipeline(tonemapped_img, label, [segment_step, crop_step])[0]\n",
    "\n",
    "print_heading(\"Segmented image\")\n",
    "plt.imshow(segmented_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pattern from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_pattern_step = curry(extract_pattern, model=cfg[\"unet\"])\n",
    "\n",
    "pattern_img, label = apply_pipeline(segmented_img, label, [extract_pattern_step])[0]\n",
    "\n",
    "print_heading(\"Pattern image\")\n",
    "plt.imshow(pattern_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_img = encode_single(pattern_img, cfg)\n",
    "print(\"Encoded image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small database for testing\n",
    "This example uses a very simple database implemented as a Python class. The database might take a lot of space if all images are used, and in that case it is better to store it on a disc, e.g. with the help of SQL based database systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dataset_mini = DatasetSlice(database_dataset, range(20))\n",
    "\n",
    "pipeline = [\n",
    "            tonemap_step, \n",
    "            segment_step, crop_step,\n",
    "            extract_pattern_step\n",
    "            ]\n",
    "\n",
    "pattern_dataset = apply_pipeline_cocodataset(database_dataset_mini, pipeline)\n",
    "\n",
    "db_components, codebooks = create_database(pattern_dataset, cfg)\n",
    "\n",
    "simple_db = SimpleDatabase(*db_components)\n",
    "print(\"Created a test database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_result = identify([(encoded_img, label)], database=simple_db, cfg=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise re-identification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_match(identification_result[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply full pipeline to another query image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = [\n",
    "            tonemap_step, \n",
    "            segment_step, crop_step,\n",
    "            extract_pattern_step,\n",
    "            curry(encode_pipeline, cfg=cfg),\n",
    "            curry(identify_single, database=simple_db, cfg=cfg),\n",
    "            visualise_match\n",
    "            ]\n",
    "\n",
    "apply_pipeline(*query_dataset[0], full_pipeline)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68004c4925163c4184023d7cef85e997c306b50ccddfa119b94259918fbcddfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('norppa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
