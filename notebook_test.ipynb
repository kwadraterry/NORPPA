{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup autoreload, warnings and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def print_heading(string):\n",
    "    display(Markdown(f\"# {string}\"))\n",
    "def print_subheading(string):\n",
    "    display(Markdown(f\"## {string}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the visibility of cuda devices (in case your system contains more than one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=\"\"\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import tensorflow as tf\n",
    "from config import config\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import wget\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from torchvision.datasets.utils import download_url\n",
    "from datasets import COCOImageDataset, DatasetSlice, SimpleDataset\n",
    "\n",
    "from norppa_tools import print_topk_accuracy, print_step, apply_pipeline, crop_step, crop_step_sequential, curry, curry_sequential, apply_sequential, apply_pipeline_dataset, get_save_step, apply_sequential, compose_sequential, calculate_accuracy, resize_dataset\n",
    "from tonemapping.tonemapping import tonemap, tonemap_step\n",
    "from segmentation.segmentation import segment\n",
    "from pattern_extraction.extract_pattern import extract_pattern\n",
    "from reidentification.identify import encode_single, encode_pipeline, encode_dataset, identify, identify_single, getDISK, getKeyNetAffNetHardNet\n",
    "from reidentification.find_matches import find_matches\n",
    "from reidentification.visualisation import visualise_match\n",
    "from reidentification.identify import apply_geometric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a configuration file.\n",
    "You can change the default parameters in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config()\n",
    "\n",
    "segment_step = curry_sequential(segment, cfg[\"seem\"], instance_segmentation=False)\n",
    "extract_pattern_step = curry_sequential(extract_pattern, model=cfg[\"unet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(cfg[\"dataset_dir\"])\n",
    "\n",
    "if not dataset_dir.exists():\n",
    "    \n",
    "    print(\"Download and extract dataset\")\n",
    "    # Get a single use download link from https://etsin.fairdata.fi/dataset/22b5191e-f24b-4457-93d3-95797c900fc0/data\n",
    "    # You will only need \"full images.zip\" for the reidentification, generate a link to that.\n",
    "    dataset_url = \"\"\n",
    "    \n",
    "    print(f'Creating directory \"{dataset_dir}\"')\n",
    "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file = wget.download(dataset_url.replace(\" \", \"%20\"), out=str(dataset_dir))\n",
    "    print()\n",
    "    print(f'Extracting \"{file}\"')\n",
    "    zip_f = zipfile.ZipFile(file, 'r')\n",
    "    zip_f.extractall(dataset_dir)\n",
    "    zip_f.close()\n",
    "    Path(file).unlink()\n",
    "\n",
    "print(f'SealID dataset is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(cfg[\"dataset_dir\"])/\"full images\"\n",
    "\n",
    "database_dataset = COCOImageDataset(dataset_dir/\"source_database\", dataset_dir/\"annotation.csv\", \"database\")\n",
    "query_dataset = COCOImageDataset(dataset_dir/\"source_query\", dataset_dir/\"annotation.csv\", \"query\")\n",
    "\n",
    "\n",
    "segmented_database_dataset = COCOImageDataset(dataset_dir/\"segmented_database\", dataset_dir/\"annotation.csv\", \"database\")\n",
    "segmented_query_dataset = COCOImageDataset(dataset_dir/\"segmented_query\", dataset_dir/\"annotation.csv\", \"query\")\n",
    "\n",
    "# tonemapped_database_dataset = COCOImageDataset(dataset_dir/\"tonemapped_segmented_database\", dataset_dir/\"annotation.csv\", \"database\")\n",
    "# tonemapped_query_dataset = COCOImageDataset(dataset_dir/\"tonemapped_segmented_query\", dataset_dir/\"annotation.csv\", \"query\")\n",
    "\n",
    "img_data = query_dataset[0]\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = img_data\n",
    "\n",
    "print_heading(\"Input image\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply tonemapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to install pfstmo package with\n",
    "# sudo apt-get install pfstmo\n",
    "\n",
    "tonemapped_img = tonemap(img)\n",
    "\n",
    "print_heading(\"Tonemapped image\")\n",
    "plt.imshow(tonemapped_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment and crop an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_step = curry_sequential(segment, cfg[\"seem\"], instance_segmentation=False)\n",
    "\n",
    "# segmented_img, label = apply_pipeline((tonemapped_img, label), [segment_step, crop_step_sequential])[0]\n",
    "segmented_img, label = apply_pipeline((img, label), [segment_step, crop_step_sequential])[0]\n",
    "\n",
    "print_heading(\"Segmented image\")\n",
    "plt.imshow(segmented_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pattern from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_pattern_step = curry_sequential(extract_pattern, model=cfg[\"unet\"])\n",
    "\n",
    "pattern_img, label = apply_pipeline((segmented_img, label), [extract_pattern_step])[0]\n",
    "\n",
    "print_heading(\"Pattern image\")\n",
    "plt.imshow(pattern_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_img = encode_single((pattern_img,label), cfg)\n",
    "print(\"Encoded image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small database for testing\n",
    "This example uses a very simple database implemented as a Python class. The database might take a lot of space if all images are used, and in that case it is better to store it on a disc, e.g. with the help of SQL based database systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dataset_mini = DatasetSlice(database_dataset, range(10))\n",
    "pipeline = [\n",
    "        # apply_sequential(tonemap_step), \n",
    "        segment_step, \n",
    "        crop_step_sequential,\n",
    "        extract_pattern_step,\n",
    "        curry(encode_dataset, cfg=cfg),\n",
    "]\n",
    "\n",
    "encoded_database = apply_pipeline_dataset(db_dataset_mini, pipeline, verbose=True)\n",
    "\n",
    "print(\"Created a test database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_result = apply_pipeline_dataset(encoded_img, [\n",
    "    curry(identify, database=encoded_database, topk=10),\n",
    "    curry_sequential(find_matches, cfg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualise_match(identification_result[0], topk=3)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do geometrical verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geom_matches = curry_sequential(apply_geometric, cfg[\"geometric\"])(identification_result)\n",
    "\n",
    "visualise_match(geom_matches[0], topk=3)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with StopwatchPrint(\"gm\"):\n",
    "    geom_matches = curry_sequential(apply_geometric, cfg[\"geometric\"])(identification_result)\n",
    "\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply full pipeline to subset of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_dataset_mini = DatasetSlice(query_dataset, range(5))\n",
    "\n",
    "pipeline = [\n",
    "            print_step(\"Starting tonemapping...\"),\n",
    "            apply_sequential(tonemap_step), \n",
    "            print_step(\"Starting segmentation...\"),   \n",
    "            segment_step,  \n",
    "            crop_step_sequential,\n",
    "            print_step(\"Starting pattern extraction...\"),  \n",
    "            extract_pattern_step,\n",
    "            \n",
    "            print_step(\"Starting encoding...\"),  \n",
    "            curry(encode_dataset, cfg=cfg),\n",
    "            \n",
    "            print_step(\"Starting identification...\"),  \n",
    "            curry(identify, database=encoded_database, topk=10),\n",
    "            curry(print_topk_accuracy, label=\"Before geometric verification:\"),\n",
    "            \n",
    "            print_step(\"Starting geometric verification...\"), \n",
    "            curry_sequential(find_matches, cfg),\n",
    "            curry_sequential(apply_geometric, cfg[\"geometric\"]),\n",
    "            curry(print_topk_accuracy, label=\"After geometric verification:\"),\n",
    "            \n",
    "            print_step(\"Starting visualisation...\"), \n",
    "            curry_sequential(visualise_match, topk=3)\n",
    "            ]\n",
    "\n",
    "identification_result = apply_pipeline_dataset(query_dataset_mini, pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying many-to-many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_dataset_mini = DatasetSlice(query_dataset, range(5))\n",
    "db_dataset_mini = DatasetSlice(database_dataset, range(5))\n",
    "\n",
    "encode_pipeline = [\n",
    "            # curry_sequential(resize_dataset, 256),\n",
    "            print_step(\"Starting tonemapping...\"),\n",
    "            # apply_sequential(tonemap_step), \n",
    "            print_step(\"Starting segmentation...\"),   \n",
    "            segment_step,  \n",
    "            crop_step_sequential,\n",
    "            print_step(\"Starting pattern extraction...\"),  \n",
    "            extract_pattern_step,\n",
    "            \n",
    "            print_step(\"Starting encoding...\"),  \n",
    "            curry(encode_dataset, group_label='class_id', cfg=cfg)]\n",
    "\n",
    "encoded_group_database = apply_pipeline_dataset(db_dataset_mini, encode_pipeline)\n",
    "\n",
    "pipeline = [*encode_pipeline, \n",
    "            \n",
    "            print_step(\"Starting identification...\"),  \n",
    "            curry(identify, database=encoded_group_database, topk=10),\n",
    "            curry(print_topk_accuracy, label=\"Before geometric verification:\"),\n",
    "            \n",
    "            print_step(\"Starting geometric verification...\"), \n",
    "            curry_sequential(find_matches, cfg),\n",
    "            # curry_sequential(apply_geometric, cfg[\"geometric\"]),\n",
    "            # curry(print_topk_accuracy, label=\"After geometric verification:\"),\n",
    "            \n",
    "            # print_step(\"Starting visualisation...\"), \n",
    "            # curry_sequential(visualise_match, topk=3)\n",
    "            ]\n",
    "\n",
    "identification_group_result = apply_pipeline_dataset(query_dataset_mini, pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_group_result[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing feature detectors + encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset_mini = DatasetSlice(query_dataset, range(10))\n",
    "db_dataset_mini = DatasetSlice(database_dataset, range(10))\n",
    "\n",
    "encode_pipeline = [\n",
    "            # curry_sequential(resize_dataset, 256),\n",
    "            print_step(\"Starting tonemapping...\"),\n",
    "            apply_sequential(tonemap_step), \n",
    "            print_step(\"Starting segmentation...\"),   \n",
    "            segment_step,  \n",
    "            crop_step_sequential,\n",
    "            print_step(\"Starting pattern extraction...\"),  \n",
    "            extract_pattern_step,\n",
    "            \n",
    "            print_step(\"Starting encoding...\"),  \n",
    "            curry(encode_dataset, init_apply_encoders=getDISK(), config=cfg)]\n",
    "\n",
    "encoded_group_database = apply_pipeline_dataset(db_dataset_mini, encode_pipeline)\n",
    "\n",
    "pipeline = [*encode_pipeline, \n",
    "            \n",
    "            print_step(\"Starting identification...\"),  \n",
    "            curry(identify, database=encoded_group_database, topk=10),\n",
    "            curry(print_topk_accuracy, label=\"Before geometric verification:\"),\n",
    "            \n",
    "            print_step(\"Starting geometric verification...\"), \n",
    "            curry_sequential(find_matches, cfg),\n",
    "            curry_sequential(apply_geometric, cfg[\"geometric\"]),\n",
    "            curry(print_topk_accuracy, label=\"After geometric verification:\"),\n",
    "            \n",
    "            print_step(\"Starting visualisation...\"), \n",
    "            curry_sequential(visualise_match, topk=3)\n",
    "            ]\n",
    "\n",
    "identification_group_result = apply_pipeline_dataset(query_dataset_mini, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import load_pickle\n",
    "\n",
    "encoded = load_pickle(\"./output/identification_norppa_pattern_HessAffNetHardNet.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pattern_with_original(data):\n",
    "    out = data.copy()\n",
    "    out[\"file\"] = data[\"file\"].replace(\"segmented_pattern_resized\", \"segmented_resized\")\n",
    "    return out\n",
    "\n",
    "pipeline = [curry_sequential(visualise_match, topk=3, data_process_func=replace_pattern_with_original, figsize=(15,10), filename=\"./output/reid_images/reid\")]\n",
    "\n",
    "viz = apply_pipeline_dataset(encoded, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset tqdm in case progress bars glitch out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "while len(tqdm._instances) > 0:\n",
    "    tqdm._instances.pop().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_dataset_mini = DatasetSlice(query_dataset, range(5))\n",
    "\n",
    "encode_pipeline = [\n",
    "            # curry_sequential(resize_dataset, 256),\n",
    "            print_step(\"Starting tonemapping...\"),\n",
    "            apply_sequential(tonemap_step), \n",
    "            print_step(\"Starting segmentation...\"),   \n",
    "            segment_step,  \n",
    "            crop_step_sequential,\n",
    "            print_step(\"Starting pattern extraction...\"),  \n",
    "            extract_pattern_step,\n",
    "            \n",
    "            print_step(\"Starting encoding...\"),  \n",
    "            # curry(encode_dataset, group_label='class_id', cfg=cfg)\n",
    "            curry(encode_dataset, cfg=cfg)\n",
    "            ]\n",
    "\n",
    "encoded = apply_pipeline_dataset(query_dataset_mini, encode_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated_fisher = encoded[0][0]\n",
    "\n",
    "# encodings = np.array([x[0] for x in encoded])\n",
    "# summed_fisher = np.sum(encodings, axis=0)\n",
    "\n",
    "# summed_fisher - aggregated_fisher\n",
    "\n",
    "encoded[0][1]['labels'][0]['ellipses'][0].shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
